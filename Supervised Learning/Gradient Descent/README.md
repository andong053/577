# Gradient Descent
	
![alt](https://blog.paperspace.com/content/images/size/w1050/2018/05/convex_cost_function.jpg)

## Definition	
Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. 
This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear 
regression). Due to its importance and ease of implementation, this algorithm is usually taught at the beginning of almost all machine 
learning courses.


Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.


# References
	
https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21
	

# Dataset
	
Random generated numberical data.

